{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNlz6Q6xqTGdvjS0FjDrEhT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmill42/streaming-data/blob/main/Getting_track_genres_from_Spotify_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Install spotipy, import the libraries we need, and set up the credentials to get data from the Spotify API. **Make sure to insert your own `client_id` and `client_secret`.**\n",
        "\n",
        "Then load the listening data. Again, replace the filepath with the path to your own data."
      ],
      "metadata": {
        "id": "N6doU6ItCkvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Spotipy"
      ],
      "metadata": {
        "id": "NKsKlOFW9DBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAD4ljDY8eL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "client_id = ''\n",
        "client_secret = ''\n",
        "\n",
        "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
        "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/COMPFOR 304/Data/BAM - Streaming_History_Audio_2013-2024.json')"
      ],
      "metadata": {
        "id": "8TQfxtul88Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting genres"
      ],
      "metadata": {
        "id": "0ZqlEBdfCwSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spotify only assigns genres to *artists*, not tracks, but our listening data only contains info on the tracks we've listened to - specifically, it contains track URIs but not artist URIs.\n",
        "\n",
        "This means that it's a multi-step process to get from track data to genre data:\n",
        "\n",
        "1. Use track URIs in our listening data to retrieve the rest of the metadata for each track, including artist URIs\n",
        "2. Use artist URIs to retrieve the rest of the metadata for each artist, including genre labels\n",
        "3. Attach the genre labels back to the track URIs via the artist URIs\n",
        "4. Attach the genre labels back to the original dataset via the track URIs\n",
        "\n",
        "Spotify only lets us request a limited number of items at once via the API, so if we want genre info for many tracks at once we need some extra code to split our data into small chunks and request their info one by one, then put all the data back together again."
      ],
      "metadata": {
        "id": "pCGG99W5nSyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def get_tracks_info(uris, sp_object, batch_size=50):\n",
        "    all_tracks = []\n",
        "    for i in range(0, len(uris), batch_size):\n",
        "        batch_uris = uris[i: i + batch_size] # Get a batch of URIs\n",
        "        tracks_batch = sp_object.tracks(batch_uris) # Fetch track info for the batch\n",
        "        all_tracks.extend(tracks_batch[\"tracks\"]) # Add batch results to the main list\n",
        "        time.sleep (0.5) # Wait for a short duration to avoid rate limiting\n",
        "    return all_tracks\n",
        "\n",
        "def get_artists_info(uris, sp_object, batch_size=50):\n",
        "    all_artists = []\n",
        "    for i in range(0, len(uris), batch_size):\n",
        "        batch_uris = uris[i: i + batch_size] # Get a batch of URIs\n",
        "        artists_batch = sp_object.artists(batch_uris) # Fetch artist info for the batch\n",
        "        all_artists.extend(artists_batch[\"artists\"]) # Add batch results to the main\n",
        "        time.sleep (0.5) # Wait for a short duration to avoid rate limiting\n",
        "    return all_artists\n"
      ],
      "metadata": {
        "id": "SD_HGvzQIkA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Narrowing down the data\n",
        "\n",
        "We'll test this on a subset of the rows using `head()` so we don't request 14k+ tracks' genres.\n",
        "\n",
        "**IF USING THIS CODE WITH YOUR OWN DATA:** You won't want to just request genre info for the first 200 tracks. But I also highly recommend NOT asking for genres for every single track you've ever listened to, as this may take a long time or cause errors with the API.\n",
        "\n",
        "Instead, you should filter your data down to a more manageable subset first, whether that's \"all the tracks I listened to while walking to class\" or \"all the tracks I listened to in the past year,\" etc. Replace `tracks_subset` with that data when doing this on your own."
      ],
      "metadata": {
        "id": "uC2j3BD4G3Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_subset = df.head(200)"
      ],
      "metadata": {
        "id": "CwBCsKsl8ptf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `uri_subset` variable stores a list of all the Spotify URIs for the tracks in the dataframe. Since many tracks will appear multiple times in the full dataset, we can drop duplicates here so we only request each song's data once."
      ],
      "metadata": {
        "id": "n2yILlcQoTK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uris = tracks_subset.spotify_track_uri.drop_duplicates()"
      ],
      "metadata": {
        "id": "H97Qy3cNoOjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Get track metadata\n",
        "\n",
        "Now we ask for the track info from the API, which will contain the artists for each track."
      ],
      "metadata": {
        "id": "SOV6HzPkHK2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks = get_tracks_info(uris, sp)"
      ],
      "metadata": {
        "id": "SbnW6Rbh8sPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we put together a table that contains only the track URIs and the artist URIs, so we don't lose track of which ones go together."
      ],
      "metadata": {
        "id": "FJZ406ZqhDjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_lists = [d['artists'] for d in tracks]\n",
        "track_uris = [d['uri'] for d in tracks]\n",
        "artist_ids = []\n",
        "\n",
        "for tn in range(len(artist_lists)):\n",
        "    for a in artist_lists[tn]:\n",
        "        artist_ids.append({'track_uri': track_uris[tn], 'artist_uri': a['uri']})\n",
        "\n",
        "track_artist_uris = pd.DataFrame(artist_ids)"
      ],
      "metadata": {
        "id": "9qSE0zWtXMQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how we now have multiple copies of some track URIs, for any tracks with multiple artists:"
      ],
      "metadata": {
        "id": "3pvnkEEXolNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "track_artist_uris"
      ],
      "metadata": {
        "id": "IiygCp7mcUTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Get artist metadata\n",
        "\n",
        "Now we can ask the API for the info for each artist using the `artist_uri` column."
      ],
      "metadata": {
        "id": "guwPmlJYiMxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artist_info = get_artists_info(track_artist_uris.artist_uri.drop_duplicates(), sp)"
      ],
      "metadata": {
        "id": "2JQX2xetdNUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we pull the genres out of the API data and create a new table that links artist URIs to their lists of genres."
      ],
      "metadata": {
        "id": "nDLi6R4llPSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artists_genres = [{'artist_uri': a['uri'], 'genres': a['genres']} for a in artist_info]\n",
        "genres_table = pd.DataFrame(artists_genres).drop_duplicates('artist_uri')"
      ],
      "metadata": {
        "id": "9wtqRrDcdjY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting table has exactly one row for each artist, each paired with a list of genres:"
      ],
      "metadata": {
        "id": "y8gSI2wUwNXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genres_table"
      ],
      "metadata": {
        "id": "gNHMCoA3wMz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Attach genre info to tracks\n",
        "\n",
        "Now we **merge** the genres onto the track URIs. In other words, we take our `track_artist_uris` table from above and use the artist URI to connect the genres from the `genres_table` back to the track URIs."
      ],
      "metadata": {
        "id": "Ddsd9t7mlW8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_with_genres = pd.merge(track_artist_uris, genres_table, how='left', on='artist_uri')"
      ],
      "metadata": {
        "id": "6Q6XqsatdaC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice here that we're back to having multiple rows for some tracks if they had multiple artists:"
      ],
      "metadata": {
        "id": "qyGlYTrFrVdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_with_genres"
      ],
      "metadata": {
        "id": "wl7rXnParUiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're trying to associate genres with tracks, it would make more sense to have a single list of genres for each track, rather than separate genre lists for each artist.\n",
        "\n",
        "Using `groupby`, we can add together all the genre lists associated with each individual track. The result will be a table with one row per track containing the track URI and its genre list."
      ],
      "metadata": {
        "id": "FSSzeMohV2Ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_with_genres = tracks_with_genres.groupby('track_uri').agg({'genres': 'sum'}).reset_index()"
      ],
      "metadata": {
        "id": "owJsvDt3URcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_with_genres"
      ],
      "metadata": {
        "id": "aQBWTSCHs3Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Attach genres back to the full dataset"
      ],
      "metadata": {
        "id": "kXajvYy0pzS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, we can merge the genres back into the larger dataset. All we need to do is line up the track URIs from the original table with the ones in our new `tracks_with_genres` table.\n",
        "\n",
        "Note that the column name for the track URI is different in the two tables even though they contain the same information, so we can use `left_on` and `right_on` arguments for the merge.\n",
        "\n",
        "The resulting table looks exactly like our original dataset, but with genres added!"
      ],
      "metadata": {
        "id": "cyorkQJDlfW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_table = pd.merge(tracks_subset, tracks_with_genres, left_on='spotify_track_uri', right_on='track_uri', how='left')"
      ],
      "metadata": {
        "id": "3gVm85NelkYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_table"
      ],
      "metadata": {
        "id": "rUMvEAcotsBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving forward: making the data easier to work with\n",
        "\n",
        "There is still a small problem with this dataset, which is that the genre column contains *lists* of genres. How we engage with this information will depend on exactly what questions we're trying to answer, but let's assume that we want to examine our listening history purely by genre.\n",
        "\n",
        "We can start by cutting our table down to just the timestamp and the genre list"
      ],
      "metadata": {
        "id": "KJCIAmhStuvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_genre_ts = full_table[['ts', 'genres']]"
      ],
      "metadata": {
        "id": "EFEaeVq5RBKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can interpret this table as saying, \"at X time and date, I was listening to genres [A, B, C], etc.\""
      ],
      "metadata": {
        "id": "C6tPDlXNuchr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_genre_ts"
      ],
      "metadata": {
        "id": "Q2IDgn-_uW-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But it'll be even easier to work with this for most purposes if we expand those genre lists out so that each genre gets its own row.\n",
        "\n",
        "The pandas `explode` method will do exactly that:"
      ],
      "metadata": {
        "id": "ML47E3J6uuT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_genre_ts = df_genre_ts.explode('genres', ignore_index=True)"
      ],
      "metadata": {
        "id": "B4H3vgNbPM_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the resulting data, we now have a column of timestamps and a column of *individual* genres. From here, we can easily apply the kinds of timestamp manipulations and filters that we covered previously."
      ],
      "metadata": {
        "id": "jT8Qm4bju-bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_genre_ts"
      ],
      "metadata": {
        "id": "eqba-EBom0ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQ3G91F_vPaV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}