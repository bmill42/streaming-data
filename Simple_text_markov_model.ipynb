{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyWNcyurapZ++eWKxj5Kvt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmill42/streaming-data/blob/main/Simple_text_markov_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from Douglas Duhaime's [tutorial](https://www.douglasduhaime.com/posts/making-chiptunes-with-markov-models.html) on Markov models for music.\n",
        "\n",
        "Import libraries we'll need later and connect Google Drive"
      ],
      "metadata": {
        "id": "HWxk0UdAnkBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ULYk4Ya6kcfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "hwD5P_fmo-mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by opening the text file containing lines from Shakespeare."
      ],
      "metadata": {
        "id": "-pr0vrDH1aZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('/content/drive/MyDrive/COMPFOR 304/Data/tiny-shakespeare.txt').read() # replace path with your own"
      ],
      "metadata": {
        "id": "t_tC035P1azQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want our model to generate entire lines all at once - things like this:\n",
        "\n",
        "```\n",
        "Character name: Here are some lines! Now the line will end and a new character will speak.\n",
        "```\n",
        "\n",
        "To do this, we'll insert some special words that will serve as **start and end tokens**, which can be used to trigger the beginning or end of the model's output.\n",
        "\n",
        "Each line spoken by a character in this file is separated by an empty line - the equivalent of typing the 'Return' key twice to start a new paragraph. New lines (technically 'newlines') are represented in plain text with a special character, `\\n`, so we can insert or replace newlines by adding or removing `\\n` in our text.\n",
        "\n",
        "We'll take advantage of this by noting that each line is separated from the others by `\\n\\n`, so anytime we see that character combination we can `replace()` it with the words `END` and `START`. Now each line is demarcated with these special tokens.\n",
        "\n",
        "The final step is to add the very first `START` and very last `END` at the beginning and end of the file, since our replacement method didn't cover these special cases."
      ],
      "metadata": {
        "id": "Gw6jHNXWgzRk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ8Y0cpXiXKo"
      },
      "outputs": [],
      "source": [
        "formatted = text.replace('\\n\\n', ' END \\n\\n START ')\n",
        "\n",
        "training_data = 'START ' + formatted + ' END'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the text is all in one long string by default, we need to split it into a list of individual words using the string method `split()`. In machine learning more generally, this process is called **tokenization** - taking a full corpus and turning into the smallest units that you want your model to \"understand\"."
      ],
      "metadata": {
        "id": "j-i1DhDffdz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = training_data.split(' ')"
      ],
      "metadata": {
        "id": "-06eYFuOie0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we create an empty dictionary that will serve as our Markov model by tracking which words follow other words.\n",
        "\n",
        "We'll use a special kind of dictionary called a `defaultdict`, which works exactly like a normal dictionary with one extra feature: if we try to refer to a key that isn't already in the dictionary, a normal `dict` would give an error, but a `defaultdict` will automatically create that key and give it a default value of whatever type we've specified - in this case, a list."
      ],
      "metadata": {
        "id": "6w_zStlDnGgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_words = defaultdict(list)"
      ],
      "metadata": {
        "id": "3IFFXil1nEIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the model"
      ],
      "metadata": {
        "id": "qq3oaYKko6xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model itself will consist of a dictionary with one key for each word in the text. The value for each key will be a list of all the words that follow that word in the corpus, including duplicates. By choosing one of those words randomly, the generated two-word sequences will match the frequencies of the sequences in the corpus.\n",
        "\n",
        "To build the model, we just have to look at every word in the corpus and keep track of which word follows it. In pseudo-code,\n",
        "\n",
        "```\n",
        "for each word n,\n",
        "    add word n+1 to word n's list\n",
        "```\n",
        "\n",
        "What this means is that we can't just loop over *every* word in the corpus, because the very last word doesn't have a word `n+1`.\n",
        "\n",
        "To loop over every word except the last one, we can take advantage of the fact that Python lets us index lists from the *end* using negative indices:"
      ],
      "metadata": {
        "id": "n-TAeFcepXre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = [1, 2, 3, 4, 5]\n",
        "my_list[-1]"
      ],
      "metadata": {
        "id": "O1Fhst7SrlxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This also works for slicing:"
      ],
      "metadata": {
        "id": "WqKpxhVirtjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list[1:-1] # take the second item through the second-to-last"
      ],
      "metadata": {
        "id": "8Lp1agnQr4H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build the model, we can just loop over a range covering the length of the list minus one, grabbing the word at the current index along with the next word. Then we add the next word to the list associated with the current word's key in the dictionary.\n",
        "\n",
        "Recall that the `defaultdict` has the convenient feature of accepting words that it's never seen before as keys by automatically creating a new entry for them."
      ],
      "metadata": {
        "id": "dct-Bb9WsAGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word_index in range(len(words[:-1])):\n",
        "    current_word = words[word_index]\n",
        "    next_word = words[word_index+1]\n",
        "\n",
        "    next_words[current_word].append(next_word)"
      ],
      "metadata": {
        "id": "D-SYqoS1oS20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examining the model\n",
        "\n",
        "Let's peek into the `next_words` dictionary by prompting it with a word:"
      ],
      "metadata": {
        "id": "f-iD00YMuUML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_words['king']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ADprOvpCuI3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever our Markov model is in the state `'king'`, it will randomly choose the next word using this list.\n",
        "\n",
        "We can get a better sense of the probabilities involved by sorting the list:"
      ],
      "metadata": {
        "id": "FbjhKwMvvGH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(next_words['king'])"
      ],
      "metadata": {
        "id": "HGupt8PcvFlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly `'I'` is much less likely than `'and'`, for example, which seems to have a similar likelihood to `'is`'. Note also that words that include punctuation like commas or periods are separate entries from the non-punctuated versions. We could tweak the preparation of the data to turn these into separate tokens, but the benefit of this version is that punctuation won't appear totally randomly - it will always be attached to words that tend to end sentences or clauses in real text.\n",
        "\n",
        "Let's examine this slightly more formally and calculate the actual probability for each word given a particular current state.\n",
        "\n",
        "**Fill out this function** that takes in a list of words (as in the above output) so that it returns a dictionary called `word_freqs` that includes each word and the proportion it represents in the list. E.g.,\n",
        "\n",
        "```\n",
        "{\n",
        "    'I': 0.01,\n",
        "    'the': 0.10,\n",
        "    'and': 0.06\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "daYYLMWOvlQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_probabilities(current_word):\n",
        "    word_freqs = dict()\n",
        "\n",
        "    # your code here\n",
        "\n",
        "    return word_freqs"
      ],
      "metadata": {
        "id": "iQZ-7vOjwl2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_probabilities('king') # test your function here"
      ],
      "metadata": {
        "id": "HN9QTdIQ8qQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we've created a dictionary associating each word with its probabilities, we can turn it into a dataframe and sort to get the most likely words. If we were to diagram this Markov model, these numbers would be the transition probabilities associated with the arrows pointing to each word:"
      ],
      "metadata": {
        "id": "gxwueVAC8b-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(word_probabilities('king').items(), columns=['next_word', 'prob']).sort_values('prob', ascending=False).reset_index(drop=True).head(10)"
      ],
      "metadata": {
        "id": "zaAh7_KM7GPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Generating new outputs"
      ],
      "metadata": {
        "id": "0qSyoAglxJ4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can sample from the model to generate new Shakespeare-ish lines.\n",
        "\n",
        "This function will start by randomly choosing a word from the `'START'` state. Since every line in the corpus starts with the name of a character, we should generally get outputs that begin with a character's name, just like in a real play.\n",
        "\n",
        "From there, the model will continually add the current word to the output string and then choose a new word using the most recent word as the model's state. The process only ends when we see the `'END'` token - which means that our lines should all come to an end eventually, but the exact length depends on the model's random choices.\n",
        "\n",
        "After testing the function as-is, **modify the `generate_lines` function so that lines can begin with any word provided by the user,** rather than just the `'START'` token. The user-specified start token should be the second argument to the function."
      ],
      "metadata": {
        "id": "3IE3FInUxoY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_line(model):\n",
        "    output = ''\n",
        "    word = random.choice(model['START'])\n",
        "\n",
        "    while word != 'END':\n",
        "        output += word + ' '\n",
        "        word = random.choice(model[word])\n",
        "\n",
        "    print(output.strip() + '\\n')\n",
        "    return"
      ],
      "metadata": {
        "id": "gBOUAKnso4el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    generate_line(next_words)"
      ],
      "metadata": {
        "id": "GVflED8IqI-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vrwEGoE1PTO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}