{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw+jwXI97+s+2xENoUeafP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmill42/streaming-data/blob/main/Merging_listening_data_and_API_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Install spotipy, import the libraries we need, and set up the credentials to get data from the Spotify API. **Make sure to insert your own `client_id` and `client_secret`.**\n",
        "\n",
        "Then load the listening data. Again, replace the filepath with the path to your own data."
      ],
      "metadata": {
        "id": "N6doU6ItCkvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Spotipy"
      ],
      "metadata": {
        "id": "NKsKlOFW9DBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAD4ljDY8eL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "client_id = ''\n",
        "client_secret = ''\n",
        "\n",
        "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
        "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** if you're using Apple Music data, skip this cell and move on to \"Getting Features for Apple Music Data\" below."
      ],
      "metadata": {
        "id": "ME-ierqbRdxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/COMPFOR 304/Data/BAM - Streaming_History_Audio_2013-2024.json')"
      ],
      "metadata": {
        "id": "8TQfxtul88Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting audio features"
      ],
      "metadata": {
        "id": "0ZqlEBdfCwSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll test this on a subset of the rows using `head()` so we don't request 14k+ tracks' audio features.\n",
        "\n",
        "The `uri_subset` variable stores a list of all the Spotify URIs for the tracks in the dataframe. Since many tracks will appear multiple times in the full dataset, we can drop duplicates here so we only request each song's features once."
      ],
      "metadata": {
        "id": "uC2j3BD4G3Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks_subset = df.head()\n",
        "uri_subset = tracks_subset.spotify_track_uri.drop_duplicates()\n",
        "uri_subset"
      ],
      "metadata": {
        "id": "CwBCsKsl8ptf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we just ask for the audio features from the API and put them in a dataframe, exactly like in the original API examples."
      ],
      "metadata": {
        "id": "SOV6HzPkHK2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft = sp.audio_features(uri_subset)\n",
        "ft_df = pd.DataFrame(ft)\n",
        "ft_df"
      ],
      "metadata": {
        "id": "SbnW6Rbh8sPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging audio features with listening data\n",
        "\n",
        "Now we **merge** the features with the listening data by asking pandas to match up the URIs in our original data with the URIs in the audio features that we downloaded."
      ],
      "metadata": {
        "id": "EFtgrKRXHS0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_merged = pd.merge(tracks_subset, ft_df, left_on='spotify_track_uri', right_on='uri')"
      ],
      "metadata": {
        "id": "KGEonFeP8vit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the columns of the resulting table, we can see that the original columns from the listening data (timestamp, track and artist name, and so on) have been augmented with the audio features, like 'danceability' and 'speechiness'."
      ],
      "metadata": {
        "id": "U84GwR_4HiOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_merged.columns"
      ],
      "metadata": {
        "id": "jN68LTew9V5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are still a lot of unneccessary columns here, so it's typically going to be best to reduce the table down to just the ones we care about.\n",
        "\n",
        "**It would be a great idea to export the data as a CSV file now and save it to your computer and Google Drive so you don't have to request the features again every time!**"
      ],
      "metadata": {
        "id": "LqrDIY20H27y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_merged[['ts', 'master_metadata_track_name', 'master_metadata_album_artist_name',\n",
        "       'master_metadata_album_album_name', 'spotify_track_uri', 'reason_end', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
        "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
        "       'valence', 'tempo', 'duration_ms']]"
      ],
      "metadata": {
        "id": "uaJw9uuU9WvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting audio features for Apple Music data"
      ],
      "metadata": {
        "id": "jNQm3lOdRAlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Apple Music data from a CSV file and split the 'Track Description' column into separate 'Artist' and 'Track Name' columns.\n",
        "\n",
        "**The rest of this code should run as-is once you enter the correct file path here.**"
      ],
      "metadata": {
        "id": "PPurJI3kS0r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_df = pd.read_csv('/content/drive/MyDrive/COMPFOR 304/Data/apple_music_test.csv')\n",
        "\n",
        "apple_df[['Artist', 'Track Name']] = apple_df['Track Description'].str.split(\" - \", expand=True, n=1)\n",
        "apple_df['spotify_uri'] = ''"
      ],
      "metadata": {
        "id": "G3bH2Tr_RZgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to go through the tracks in the Apple Music data one by one and collect their Spotify URIs, which will then allow us to collect the audio features just like in the above example for the native Spotify data.\n",
        "\n",
        "We'll do this by looping over every track and using the Spotify API to do a *search* - essentially the same as typing a track and artist name into the search bar in the Spotify app. We will select the first track that comes up in the search and grab its URI.\n",
        "\n",
        "This is an imperfect approach since a search is not guaranteed to turn up the right track for multiple reasons: an artist may have recorded the same song multiple times, e.g. on both live and studio albums; a track may be on Apple Music but not Spotify; or metadata issues may make the actual artist of a track ambiguous, as will probably happen often with classical music.\n",
        "\n",
        "In these kinds of cases, the top result for our search will likely be the wrong track, and we'll end up with the wrong URI - in some cases potentially for a track from an entirely different artist. This will degrade the quality of our data, but if the number of problematic tracks is small enough it likely won't affect the quality of any resulting analysis too much."
      ],
      "metadata": {
        "id": "KcN-s_bVTKFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_dict = apple_df[['Artist', 'Track Name']].drop_duplicates().to_dict(orient='records')\n",
        "\n",
        "for r in apple_dict:\n",
        "    search_results = sp.search(q='track:' + r['Track Name'] + ' artist:' + r['Artist'], type='track')\n",
        "    best_uri = search_results['tracks']['items'][0]['uri']\n",
        "    r['uri'] = best_uri"
      ],
      "metadata": {
        "id": "bniysxIXJpnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we just turn the dictionary containing the track and artist names and URIs into a dataframe and merge it back into the original Apple Music data."
      ],
      "metadata": {
        "id": "ODsn028v0llH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri_df = pd.DataFrame(apple_dict)\n",
        "apple_merged = pd.merge(apple_df, uri_df, on=['Artist', 'Track Name'])"
      ],
      "metadata": {
        "id": "MI5PfGVxRVJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, the process is identical to the Spotify example above: isolate the list of URIs, request the audio features via the API, turn the results into a dataframe and merge it back into the full dataset."
      ],
      "metadata": {
        "id": "UvDcAwTh2QLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_uris = apple_merged.uri\n",
        "\n",
        "apple_ft = sp.audio_features(apple_uris)\n",
        "apple_ft_df = pd.DataFrame(apple_ft)"
      ],
      "metadata": {
        "id": "8DCF9-JlSGIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple_final = pd.merge(apple_merged, apple_ft_df, on='uri')"
      ],
      "metadata": {
        "id": "MGunWYz2SZBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final merged dataset still contains some of the extraneous columns that came with the API call, like some URLs that are not useful for our purposes; at this point it would make sense to clean up the full table before continuing to work with it.\n",
        "\n",
        "**It would be a great idea to export the data as a CSV file now and save it to your computer and Google Drive so you don't have to request the features again every time!**"
      ],
      "metadata": {
        "id": "vsJy_lFp2GaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_final"
      ],
      "metadata": {
        "id": "1edjjqZgSjXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1bgn4F52DyL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}